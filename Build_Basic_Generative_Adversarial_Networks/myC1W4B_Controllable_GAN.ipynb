{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c7a85d-9295-4236-8058-07af9fdd9219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks.progress import TQDMProgressBar\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from gans import ControllableGAN, CelebADataModule\n",
    "from gans.models.ControllableGAN import get_noise, calculate_updated_noise, get_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048aad6b-08b1-41f7-8104-967a96548f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = TensorBoardLogger(\"logs\", name = \"ControllableGAN\")\n",
    "\n",
    "celeba = CelebADataModule(batch_size=128)\n",
    "model = ControllableGAN(pretrained=True)\n",
    "\n",
    "opt = torch.optim.Adam(model.classifier.parameters(), lr=0.01)\n",
    "\n",
    "# trainer = Trainer(\n",
    "#     accelerator=\"auto\",\n",
    "#     devices=1 if torch.cuda.is_available() else None,  # limiting got iPython runs\n",
    "#     max_epochs=70,\n",
    "#     callbacks=[TQDMProgressBar(refresh_rate=20)],\n",
    "#     logger=logger,\n",
    "# )\n",
    "# trainer.fit(model, celeba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd04f17-42f8-4973-ac31-abd050749071",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "    \n",
    "def show_tensor_images(image_tensor, num_images=16, size=(3, 64, 64), nrow=3):\n",
    "    '''\n",
    "    Function for visualizing images: Given a tensor of images, number of images, and\n",
    "    size per image, plots and prints the images in an uniform grid.\n",
    "    '''\n",
    "    image_tensor = (image_tensor + 1) / 2\n",
    "    image_unflat = image_tensor.detach().cpu()\n",
    "    image_grid = make_grid(image_unflat[:num_images], nrow=nrow)\n",
    "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc0a317-f98d-4744-9a75-af9658d4a07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First generate a bunch of images with the generator\n",
    "z_dim = 64\n",
    "n_images = 8\n",
    "fake_image_history = []\n",
    "grad_steps = 10 # Number of gradient steps to take\n",
    "skip = 2 # Number of gradient steps to skip in the visualization\n",
    "\n",
    "feature_names = [\"5oClockShadow\", \"ArchedEyebrows\", \"Attractive\", \"BagsUnderEyes\", \"Bald\", \"Bangs\",\n",
    "\"BigLips\", \"BigNose\", \"BlackHair\", \"BlondHair\", \"Blurry\", \"BrownHair\", \"BushyEyebrows\", \"Chubby\",\n",
    "\"DoubleChin\", \"Eyeglasses\", \"Goatee\", \"GrayHair\", \"HeavyMakeup\", \"HighCheekbones\", \"Male\", \n",
    "\"MouthSlightlyOpen\", \"Mustache\", \"NarrowEyes\", \"NoBeard\", \"OvalFace\", \"PaleSkin\", \"PointyNose\", \n",
    "\"RecedingHairline\", \"RosyCheeks\", \"Sideburn\", \"Smiling\", \"StraightHair\", \"WavyHair\", \"WearingEarrings\", \n",
    "\"WearingHat\", \"WearingLipstick\", \"WearingNecklace\", \"WearingNecktie\", \"Young\"]\n",
    "\n",
    "### Change me! ###\n",
    "target_indices = feature_names.index(\"Smiling\") # Feel free to change this value to any string from feature_names!\n",
    "other_indices = [cur_idx != target_indices for cur_idx, _ in enumerate(feature_names)]\n",
    "noise = get_noise(n_images, z_dim).requires_grad_()\n",
    "original_classifications = model.classifier(model.generator(noise)).detach()\n",
    "\n",
    "for i in range(grad_steps):\n",
    "    opt.zero_grad()\n",
    "    fake = model.generator(noise)\n",
    "    fake_image_history += [fake]\n",
    "    fake_score = get_score(\n",
    "    model.classifier(fake), \n",
    "    original_classifications,\n",
    "    target_indices,\n",
    "    other_indices,\n",
    "    penalty_weight=0.1\n",
    "    )\n",
    "    fake_score.backward()\n",
    "    noise.data = calculate_updated_noise(noise, 1 / grad_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c91e7c6-387d-4b53-93ec-2c10f2e86d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [n_images * 2, grad_steps * 2]\n",
    "show_tensor_images(torch.cat(fake_image_history[::skip], dim=2), num_images=n_images, nrow=n_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38822d2-0f82-47de-a88c-359610c26d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1495dfd1ba3abd3e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1495dfd1ba3abd3e\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 8889;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Start tensorboard.\n",
    "os.environ['TENSORBOARD_BINARY'] = '/.../anaconda3/envs/pytorch/bin/tensorboard'\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir gans_logs/ --port 8889 --bind_all"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
